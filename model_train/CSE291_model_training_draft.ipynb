{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jcNNs3WzD1Iz"
   },
   "outputs": [],
   "source": [
    "# imports -----------------------------------------------------------------\n",
    "import librosa\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as T_vision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize directories ----------------------------------------------------\n",
    "cwd = os.getcwd()\n",
    "# stores train fricative spectrogram images for all sentences and speakers\n",
    "spg_train_dir = cwd + '/spg_data/train/'\n",
    "\n",
    "# stores val fricative spectrogram images for all sentences and speakers\n",
    "spg_val_dir = cwd + '/spg_data/val/'\n",
    "\n",
    "# create datasets and dataloaders -----------------------------------------\n",
    "train_ds = datasets.ImageFolder(root=spg_train_dir, \n",
    "                                transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_ds, batch_size=64)\n",
    "\n",
    "val_ds = datasets.ImageFolder(root=spg_val_dir, \n",
    "                                transform=transforms.ToTensor())\n",
    "val_loader = DataLoader(val_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-q7hfrQuEzzO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**setup note** using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA --------------------------------------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('**setup note** using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DgR76OHKE0D0"
   },
   "outputs": [],
   "source": [
    "# CNN model ---------------------------------------------------------------\n",
    "class TwoLayerCNN(nn.Module):\n",
    "  def __init__(self, c1, c2, c3):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=c1, out_channels=c2, kernel_size=3, stride=1, padding=0)\n",
    "    self.conv2 = nn.Conv2d(in_channels=c2, out_channels=c3, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    self.maxPool1 = nn.MaxPool2d((4,3), stride=(1,3))\n",
    "    self.maxPool2 = nn.MaxPool2d((1,3), stride=(1,3))\n",
    "\n",
    "    self.fc1 = nn.Linear(in_features=8, out_features=2)\n",
    "    self.fc2 = nn.Linear(in_features=2, out_features=2)\n",
    "\n",
    "  def forward(self, x):\n",
    "    #   1. conv ReLU\n",
    "    x = self.relu(self.conv1(x))\n",
    "    #   2. maxpooling, dropout 50%\n",
    "    x = self.dropout(self.maxPool1(x))\n",
    "    #   3. conv ReLU\n",
    "    x = self.relu(self.conv2(x))\n",
    "    #   4. maxpooling\n",
    "    x = self.maxPool2(x)\n",
    "    #   5. FC ReLU, dropout 50%\n",
    "    x = self.dropout(self.relu(self.fc1(x)))\n",
    "    #   6. FC ReLU, dropout 50%\n",
    "    x = self.dropout(self.relu(self.fc2(x)))\n",
    "    #   7. softmax\n",
    "    # softmax is already included in pytorch entropy loss func, so no need\n",
    "    # to add it here\n",
    "    return x\n",
    "  \n",
    "def validate(model, device, val_loader):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for input, target in val_loader:\n",
    "      input = input.to(device)\n",
    "      target = target.to(device)\n",
    "\n",
    "      output = model(input)\n",
    "      _, prediction = output.max(axis=1)\n",
    "      correct += (prediction == target).sum()\n",
    "      total += prediction.size(0)\n",
    "\n",
    "    accuracy = float(correct)/total\n",
    "  \n",
    "  return accuracy\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, val_loader, lr, m, wd, epochs,\n",
    "           print = 100):\n",
    "  loss_curve = []\n",
    "  acc_curve = []\n",
    "\n",
    "  model = model.to(device)\n",
    "  model.train()\n",
    "  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=m,\n",
    "                         weight_decay=wd, nesterov=True)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    for iter, (input, target) in enumerate(train_loader):\n",
    "      input = input.to(device)\n",
    "      target = target.to(device)\n",
    "\n",
    "      output = model(input)\n",
    "      loss = nn.functional.cross_entropy(output, target)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      loss_curve.append(loss.item())\n",
    "\n",
    "      # TODO: can move to print block if too slow        \n",
    "      accuracy = validate(model, device, val_loader)\n",
    "      acc_curve.append(accuracy)\n",
    "\n",
    "\n",
    "      if (iter+1) % print == 0:\n",
    "        print(f'Running Epoch {epoch} and Iteration {iter}: Loss is {loss.item()}')\n",
    "\n",
    "        print(f'Accuracy against validation set is {accuracy}')\n",
    "\n",
    "  return loss_curve, acc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoLayerCNN(\n",
      "  (conv1): Conv2d(3, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(1024, 2, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (maxPool1): MaxPool2d(kernel_size=(4, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (maxPool2): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=8, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of size: : [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m TwoLayerCNN(channel1, channel2, num_classes)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m---> 12\u001b[0m loss_curve, acc_curve \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 72\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, val_loader, lr, m, wd, epochs, print)\u001b[0m\n\u001b[0;32m     69\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     71\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     75\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\17397\\miniforge3\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of size: : [2]"
     ]
    }
   ],
   "source": [
    "layers = 1\n",
    "channel1 = 3\n",
    "channel2 = 1024\n",
    "num_classes = 2\n",
    "lr = 0.002\n",
    "m = 0.9\n",
    "wd = 0.001\n",
    "epochs = 300\n",
    "\n",
    "model = TwoLayerCNN(channel1, channel2, num_classes)\n",
    "print(model)\n",
    "loss_curve, acc_curve = train(model, device, train_loader, val_loader, lr, m, wd, epochs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
